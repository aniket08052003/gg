{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1acdeaf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964592e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"Admission_Predict.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2776fdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# first 5 instances of dataset\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd3e0c4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# last 5 instances of dataset\n",
    "\n",
    "data.tail()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388e5cde",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Shape of dataframe\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be96238f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#columns in dataframe\n",
    "\n",
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2a80283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# droping Id column\n",
    "\n",
    "data.drop(\"Serial No.\",axis=1,inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063eca38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Dataset\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf64b08",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Applying  necessary function on \"Chance of Admit\"\n",
    "\n",
    "data[\"Chance of Admit \"]=data[\"Chance of Admit \"].apply(lambda x: 1 if x>0.5 else 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f5ee4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking Dataset\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8017c3eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Find missing values\n",
    "print(\"Missing values:\\n\")\n",
    "data.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfcf8fb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# info about dataset\n",
    "\n",
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "851aa187",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation among dataset\n",
    "\n",
    "data.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37af02c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Correlation heatmap\n",
    "\n",
    "plt.figure(figsize=(6,6))\n",
    "sns.heatmap(data.corr(), annot=True, cmap='Oranges')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53cf09b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.hist(bins = 50,figsize = (15,11));"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20152116",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculating total Count\n",
    "\n",
    "data_admit = data[data['Chance of Admit ']==1]\n",
    "data_non_admit = data[data['Chance of Admit ']==0]\n",
    "print(\"Admitted count       : \" ,data_admit.shape[0])\n",
    "print(\"Non - Admitted count : \" ,data_non_admit.shape[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93d84be0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart for \"Chance of Admit\"\n",
    "\n",
    "data['Chance of Admit '].value_counts().plot(kind='pie',figsize=(5,5),autopct='%1.1f%%')\n",
    "plt.title(\"Chance of Admit in total\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2933c843",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart for LOR\n",
    "\n",
    "data['LOR '].value_counts().plot(kind='pie',figsize=(5,5),autopct='%1.1f%%')\n",
    "plt.title(\"LOR Point Chart\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a7608c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart for SOP\n",
    "\n",
    "data['SOP'].value_counts().plot(kind='pie',figsize=(5,5),autopct='%1.1f%%')\n",
    "plt.title(\"SOP Point Chart\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77dfb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pie chart for \"University Rating\"\n",
    "\n",
    "data[\"University Rating\"].value_counts().plot(kind='pie',figsize=(5,5),autopct='%1.1f%%')\n",
    "plt.title(\"University Rating Chart\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24290eb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#highest GRE score\n",
    "print(\"maximum GRE Score : \",data['GRE Score'].max())\n",
    "#lowest GRE score\n",
    "print(\"minimum GRE Score : \",data['GRE Score'].min())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d206e5e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot based on hue = \"Research\"\n",
    "\n",
    "sns.pairplot(data,hue = \"Research\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "991f04b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot based on hue = \"SOP\"\n",
    "\n",
    "sns.pairplot(data,hue = \"SOP\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d9fd9cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot based on hue = \"University Rating\"\n",
    "\n",
    "sns.pairplot(data,hue = \"University Rating\");"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ed35de",
   "metadata": {},
   "outputs": [],
   "source": [
    "#pairplot for dataset\n",
    "\n",
    "sns.pairplot(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c392066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dependent and independent feature\n",
    "\n",
    "X= data.drop(\"Chance of Admit \",axis =1 )\n",
    "y= data[\"Chance of Admit \"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b3be310",
   "metadata": {},
   "outputs": [],
   "source": [
    "# unique in independent feature\n",
    "\n",
    "X.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2456c993",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the dataset into train and test sets: 80-20 split\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,test_size = 0.2, random_state=42)\n",
    "\n",
    "# Shape of train Test Split\n",
    "print(X_train.shape,y_train.shape)\n",
    "print(X_test.shape,y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11bd8b2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Decision Tree Classifier model \n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate the model \n",
    "tree = DecisionTreeClassifier()\n",
    "\n",
    "# fit the model \n",
    "tree.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049d78d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting the target value from the model for the samples\n",
    "\n",
    "y_train_tree = tree.predict(X_train)\n",
    "y_test_tree = tree.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "604ec49f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "#computing the accuracy of the model performance\n",
    "acc_train_tree = accuracy_score(y_train,y_train_tree)\n",
    "acc_test_tree = accuracy_score(y_test,y_test_tree)\n",
    "\n",
    "\n",
    "print(\"Decision Tree : Accuracy on training Data: {:.3f}\".format(acc_train_tree))\n",
    "print(\"Decision Tree : Accuracy on test Data: {:.3f}\".format(acc_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e585feb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "#computing the classification report of the model\n",
    "\n",
    "print(classification_report(y_test, y_test_tree))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f25538",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.barh(X.columns,tree.feature_importances_)\n",
    "plt.title(\"Feature Importances while constructing Tree\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf474b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#visualization of Confusion Matrix \n",
    "from sklearn.metrics import confusion_matrix\n",
    "cm=confusion_matrix(y_test,y_test_tree)\n",
    "cmn = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "fig, ax = plt.subplots(figsize=(4,4))\n",
    "sns.heatmap(cmn, annot=True, fmt='.2f',cmap='Oranges')\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.ylabel('Actual')\n",
    "plt.xlabel('Predicted')\n",
    "plt.show(block=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a13cf05c",
   "metadata": {},
   "outputs": [],
   "source": [
    "training_accuracy = []\n",
    "test_accuracy = []\n",
    "# try max_depth from 1 to 15\n",
    "depth = range(1,16)\n",
    "for n in depth:\n",
    "    tree_test = DecisionTreeClassifier(max_depth=n)\n",
    "    tree_test.fit(X_train, y_train)\n",
    "    # record training set accuracy\n",
    "    training_accuracy.append(tree_test.score(X_train, y_train))\n",
    "    # record generalization accuracy\n",
    "    test_accuracy.append(tree_test.score(X_test, y_test))\n",
    "    \n",
    "\n",
    "#plotting the training & testing accuracy for max_depth from 1 to 15\n",
    "plt.plot(depth, training_accuracy, label=\"training accuracy\")\n",
    "plt.plot(depth, test_accuracy, label=\"test accuracy\")\n",
    "plt.title(\"Accuracy vs max_depth\")\n",
    "plt.ylabel(\"Accuracy\")  \n",
    "plt.xlabel(\"max_depth\")\n",
    "plt.legend();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f85296b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.tree import export_text\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "# instantiate the model \n",
    "tree = DecisionTreeClassifier(max_depth=3)\n",
    "\n",
    "# fit the model \n",
    "tree.fit(X_train, y_train)\n",
    "text_representation = export_text(tree)\n",
    "print(text_representation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4665fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualiazation of tree\n",
    "\n",
    "import sklearn.tree as tr\n",
    "fig = plt.figure(figsize=(20,15))\n",
    "_ = tr.plot_tree(tree, \n",
    "                 feature_names=X.columns,  \n",
    "                 class_names=np.array([\"Non admit\",\"Admit\"]),\n",
    "                 filled=True)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
